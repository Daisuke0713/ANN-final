{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Convolutional GANs (DCGANs) for MNIST digits and fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of how DCAGNs build on top of the basic GANs\n",
    "\n",
    "1. Rather than fully-connected or pooling layers, we use strided convoltuions (for discriminator) and transposed convolutions (for generator). \n",
    "2. We use batch-normalization layers in both generator and discriminator to faster and more stable training. \n",
    "3. We use LeakyReLU as the alternative of ReLU to prevent the zero learning problem of ReLU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Git repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Daisuke0713/ANN-final.git\n",
    "%cd ./content/ANN-final/VAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 11:49:31.750125: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras, random, nn\n",
    "from tensorflow import data\n",
    "from keras import Model, Sequential\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, Conv2DTranspose, Reshape, Flatten, BatchNormalization, ReLU, LeakyReLU, Dropout, InputLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU/CPU Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 11:49:37.184945: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "gpu_device = tf.test.gpu_device_name()\n",
    "cpu_device = '/cpu:0'\n",
    "# set CPU the device for now\n",
    "device = gpu_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpu_device != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(gpu_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "latent_dim = 128\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "(x_train_digits, _), (x_test_digits, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# process data\n",
    "def preprocess_digits_image_data(data):\n",
    "    # reshape, normalize, and binarize (gray) data\n",
    "    shape = data.shape\n",
    "    image_data = (data.reshape((shape[0], shape[1], shape[2], 1)) / 255. - 0.5) * 2.0\n",
    "    return image_data.astype('float32')\n",
    "\n",
    "x_train_digits = preprocess_digits_image_data(x_train_digits)\n",
    "x_test_digits = preprocess_digits_image_data(x_test_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_batch(image_data, batch_size):\n",
    "    data_size = len(image_data)\n",
    "    return (data.Dataset.from_tensor_slices(image_data).shuffle(data_size).batch(batch_size))\n",
    "\n",
    "# split data into batches\n",
    "x_train_digits = split_batch(image_data=x_train_digits, batch_size=batch_size)\n",
    "x_test_digits  = split_batch(image_data=x_test_digits, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential([\n",
    "    # input\n",
    "    Dense(units=7*7*128, input_shape=(latent_dim,)),\n",
    "    Reshape((7,7,128)),\n",
    "    # conv 1\n",
    "    Conv2DTranspose(filters=512, kernel_size=3, strides=2, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    ReLU(max_value=0.2),\n",
    "    # conv 2\n",
    "    Conv2DTranspose(filters=512, kernel_size=3, strides=2, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    ReLU(max_value=0.2),\n",
    "    # final tanh    \n",
    "    Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential([\n",
    "    # conv 1\n",
    "    Conv2D(filters=512, kernel_size=3, strides=2, padding='same', input_shape=(28,28,1)),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "    # conv 2\n",
    "    Conv2D(filters=512, kernel_size=3, strides=2, padding='same', input_shape=(28,28,1)),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "    # conv 3\n",
    "    Conv2D(filters=512, kernel_size=3, strides=2, padding='same', input_shape=(28,28,1)),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "    # output\n",
    "    Flatten(),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge G and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(optimizer=Adam(learning_rate=learning_rate), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
    "discriminator.trainable = False\n",
    "gan = Sequential([\n",
    "    generator, \n",
    "    discriminator\n",
    "])\n",
    "gan.compile(optimizer=Adam(learning_rate=learning_rate), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "real = np.ones(shape=(batch_size, 1))\n",
    "fake = np.zeros(shape=(batch_size, 1))\n",
    "\n",
    "with tf.device(device_name=device):\n",
    "    for epoch in range(epochs):\n",
    "        for real_x in x_train_digits:\n",
    "            # discriminator\n",
    "            discriminator.trainable = True\n",
    "\n",
    "            # train on real data\n",
    "            d_loss_real = discriminator.train_on_batch(x=real_x, y=real)\n",
    "\n",
    "            # train on fake data\n",
    "            z = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n",
    "            fake_x = generator.predict_on_batch(x=z)\n",
    "            d_loss_fake = discriminator.train_on_batch(x=fake_x, y=fake)\n",
    "            d_loss = np.mean(d_loss_real + d_loss_fake)\n",
    "\n",
    "            # generator\n",
    "            discriminator.trainable = False\n",
    "            g_loss = gan.train_on_batch(x=z, y=real)\n",
    "\n",
    "        print(f'Epoch: {epoch}, Loss G: {g_loss[-1]}, Loss D: {d_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    with tf.device(device):\n",
    "        ramdom_vector_z = np.random.normal(loc=0, scale=1, size=(16, latent_dim))\n",
    "        generated = generator(ramdom_vector_z)\n",
    "        return generated\n",
    "\n",
    "def save_img(imgs, filename):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    # plt.savefig(f'./images/{filename}.png')\n",
    "\n",
    "generated = generate()\n",
    "save_img(generated, None)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88bb0f5aeba86b8857a89854e1b72d899daa3df0ccd17c65f10c2af66593c562"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
