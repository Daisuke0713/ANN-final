{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Convolutional GANs (DCGANs) for MNIST digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of how DCAGNs build on top of the basic GANs\n",
    "\n",
    "1. Rather than fully-connected or pooling layers, we use strided convoltuions (for discriminator) and transposed convolutions (for generator). \n",
    "2. We use batch-normalization layers in both generator and discriminator to faster and more stable training. \n",
    "3. We use LeakyReLU as the alternative of ReLU to prevent the zero learning problem of ReLU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Git repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Daisuke0713/ANN-final.git\n",
    "%cd ./ANN-final/DCGANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 22:45:44.844403: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras, random, nn\n",
    "from tensorflow import data\n",
    "from keras import Model, Sequential\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers \n",
    "from keras.layers import Dense, Conv2D, Conv2DTranspose, Reshape, Flatten, BatchNormalization, ReLU, LeakyReLU, Dropout, InputLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU/CPU Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 22:45:51.537370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "gpu_device = tf.test.gpu_device_name()\n",
    "cpu_device = '/cpu:0'\n",
    "# set CPU the device for now\n",
    "device = cpu_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpu_device != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(gpu_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "latent_dim = 2\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "(x_train_digits, _), (x_test_digits, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# process data\n",
    "def preprocess_digits_image_data(data):\n",
    "    # reshape, normalize, and binarize (gray) data\n",
    "    shape = data.shape\n",
    "    image_data = (data.reshape((shape[0], shape[1], shape[2], 1)) / 255. - 0.5) * 2.0\n",
    "    return image_data.astype('float32')\n",
    "\n",
    "x_train_digits = preprocess_digits_image_data(x_train_digits)\n",
    "x_test_digits = preprocess_digits_image_data(x_test_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_batch(image_data, batch_size):\n",
    "    data_size = len(image_data)\n",
    "    return (data.Dataset.from_tensor_slices(image_data).shuffle(data_size).batch(batch_size))\n",
    "\n",
    "# split data into batches\n",
    "x_train_digits = split_batch(x_train_digits, batch_size)\n",
    "x_test_digits  = split_batch(x_test_digits, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential([\n",
    "    # input\n",
    "    Dense(units=7*7*128, input_shape=(latent_dim,)),\n",
    "    Reshape((7,7,128)),\n",
    "    # conv 1\n",
    "    Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    ReLU(max_value=0.2),\n",
    "    # conv 2\n",
    "    Conv2DTranspose(filters=64, kernel_size=3, strides=1, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    ReLU(max_value=0.2),\n",
    "    # final tanh    \n",
    "    Conv2DTranspose(filters=1, kernel_size=3, strides=2, padding='same', activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential([\n",
    "    # conv 1\n",
    "    Conv2D(filters=64, kernel_size=3, strides=2, padding='same', input_shape=(28,28,1)),\n",
    "    LeakyReLU(0.2),\n",
    "    # conv 2\n",
    "    Conv2D(filters=64, kernel_size=3, strides=2, padding='same'),\n",
    "    # BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "    # output\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge G and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(optimizer=Adam(learning_rate=learning_rate), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
    "discriminator.trainable = False\n",
    "gan = Sequential([\n",
    "    generator, \n",
    "    discriminator\n",
    "])\n",
    "gan.compile(optimizer=Adam(learning_rate=learning_rate), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    with tf.device(device):\n",
    "        ramdom_vector_z = np.random.normal(loc=0, scale=1, size=(16, latent_dim))\n",
    "        generated = generator(ramdom_vector_z)\n",
    "        return generated\n",
    "\n",
    "def save_img(imgs, filename):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(f'./images/{filename}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "real = np.ones(shape=(batch_size, 1))\n",
    "fake = np.zeros(shape=(batch_size, 1))\n",
    "\n",
    "with tf.device(device_name=device):\n",
    "    for epoch in range(epochs):\n",
    "        batch = 0\n",
    "        for real_x in x_train_digits:\n",
    "            '''discriminator'''\n",
    "\n",
    "            # train on real data\n",
    "            d_loss_real = discriminator.train_on_batch(x=real_x, y=real)\n",
    "\n",
    "            # train on fake data\n",
    "            z = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n",
    "            fake_x = generator.predict_on_batch(x=z)\n",
    "            d_loss_fake = discriminator.train_on_batch(x=fake_x, y=fake)\n",
    "            d_loss = np.mean(d_loss_real + d_loss_fake)\n",
    "\n",
    "            '''generator'''\n",
    "            g_loss = gan.train_on_batch(x=z, y=real)\n",
    "\n",
    "            batch += 1\n",
    "            # print(f'[Progress: {100*batch//len(x_train_digits)}%] Epoch: {epoch}', end='\\r')\n",
    "        print(f'Epoch: {epoch}, Loss G: {g_loss[-1]:.3f}, Loss D: {d_loss:.3f}')\n",
    "        \n",
    "        # sample and save images\n",
    "        if epoch in [0,10,20,30,40,49]:\n",
    "            save_img(generate(), f'samples_latent{latent_dim}_epoch{epoch}')\n",
    "\n",
    "gan.save('./saved')\n",
    "# Note 1 min per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r ./images.zip images\n",
    "!zip -r ./saved_models.zip saved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize latent dim\n",
    "def show_latent_image(n):\n",
    "    std_normal = tfp.distributions.Normal(0,1)\n",
    "    x = std_normal.quantile(np.linspace(0.05, 0.95, n))\n",
    "    y = std_normal.quantile(np.linspace(0.05, 0.95, n))\n",
    "    size = 28 * n\n",
    "    latent_image = np.zeros(shape=(size, size))\n",
    "\n",
    "    for i, y_i in enumerate(x):\n",
    "        for j, x_i in enumerate(y):\n",
    "            latent_z = np.array([[x_i, y_i]])\n",
    "            generated_x = tf.reshape(generator(latent_z)[0], (28,28)).numpy()\n",
    "            latent_image[i*28:(i+1)*28, j*28:(j+1)*28] = generated_x\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(latent_image, cmap='gray')\n",
    "    plt.axis('Off')\n",
    "    plt.savefig(f'./latent.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the learned latent space\n",
    "show_latent_image(n=30)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88bb0f5aeba86b8857a89854e1b72d899daa3df0ccd17c65f10c2af66593c562"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
