{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional VAEs for MNIST handwritten-digits and fashion datset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "Implemented based on the following references: <br>\n",
    "    (1) https://www.tensorflow.org/tutorials/generative/cvae <br>\n",
    "    (2) https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73 <br>\n",
    "    (3) https://arxiv.org/pdf/1907.08956.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warnings\n",
    "This Jupyter notebook is assumed to be executed on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GitHub repo clone/pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Daisuke0713/ANN-final.git\n",
    "%cd ./content/ANN-final/VAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras, random, nn\n",
    "from tensorflow import data\n",
    "from keras import Model, Sequential, optimizers, metrics\n",
    "from keras.layers import InputLayer, Dense, Conv2D, Conv2DTranspose, Reshape, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU/CPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = tf.test.gpu_device_name()\n",
    "cpu_device = '/cpu:0'\n",
    "# set CPU the device for now\n",
    "device = gpu_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpu_device != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(gpu_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congif Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "latent_dim = 128\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "(x_train_digits, _), (x_test_digits, _) = keras.datasets.mnist.load_data()\n",
    "(x_train_fashion, _), (x_test_fashion, _) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "def preprocess_digits_image_data(data):\n",
    "    # reshape, normalize, and binarize (gray) data\n",
    "    shape = data.shape\n",
    "    image_data = data.reshape((shape[0], shape[1], shape[2], 1)) / 255.\n",
    "    return np.where(image_data < 0.5, 0.0, 1.0).astype('float32')\n",
    "\n",
    "def preprocess_fashion_image_data(data):\n",
    "    # reshape and normalize\n",
    "    shape = data.shape\n",
    "    image_data = data.reshape((shape[0], shape[1], shape[2], 1)) / 255.\n",
    "    return image_data.astype('float32')\n",
    "\n",
    "# preprocess data\n",
    "x_train_digits = preprocess_digits_image_data(x_train_digits)\n",
    "x_test_digits = preprocess_digits_image_data(x_test_digits)\n",
    "\n",
    "x_train_fashion = preprocess_fashion_image_data(x_train_fashion)\n",
    "x_test_fashion = preprocess_fashion_image_data(x_test_fashion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_batch(image_data, batch_size):\n",
    "    data_size = len(image_data)\n",
    "    return (data.Dataset.from_tensor_slices(image_data).shuffle(data_size).batch(batch_size))\n",
    "\n",
    "# split data into batches\n",
    "x_train_digits = split_batch(image_data=x_train_digits, batch_size=batch_size)\n",
    "x_test_digits  = split_batch(image_data=x_test_digits, batch_size=batch_size)\n",
    "\n",
    "x_train_fashion = split_batch(image_data=x_train_fashion, batch_size=batch_size)\n",
    "x_test_fashion  = split_batch(image_data=x_test_fashion, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define VAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Basic Convolutional VAE'''\n",
    "class VAE(Model):\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = self.generate_encoder()\n",
    "        self.decoder = self.generate_decoder()\n",
    "\n",
    "    def generate_encoder(self):\n",
    "        return Sequential([\n",
    "            InputLayer(input_shape=(28, 28, 1)),\n",
    "            Conv2D(filters=512, kernel_size=3, strides=(2,2), activation='relu'),\n",
    "            Conv2D(filters=512, kernel_size=3, strides=(2,2), activation='relu'),\n",
    "            Flatten(),\n",
    "            # because the output of encoder has two parts, the mean and \n",
    "            # log-variance of the posterior distribution q(z|x)\n",
    "            Dense(self.latent_dim * 2)\n",
    "        ])\n",
    "    \n",
    "    def generate_decoder(self):\n",
    "        return Sequential([\n",
    "            # the input to decoder is z sampled from the Gaussian (through \n",
    "            # reparameterization trick)\n",
    "            InputLayer(input_shape=(self.latent_dim,)),\n",
    "            Dense(units=32*7*7, activation='relu'),\n",
    "            Reshape(target_shape=(7,7,32)),\n",
    "            Conv2DTranspose(filters=512, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "            Conv2DTranspose(filters=512, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "            Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same')\n",
    "        ])\n",
    "\n",
    "    def encode(self, x):\n",
    "        with tf.device(device):\n",
    "            mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "            return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        with tf.device(device):\n",
    "            e = random.normal(shape=mean.shape)\n",
    "            z = mean + e * tf.exp(logvar * 0.5)\n",
    "            return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        with tf.device(device):\n",
    "            xhat = self.decoder(z)\n",
    "            return xhat\n",
    "    \n",
    "    '''used during inference'''\n",
    "    def sample(self, rand_vec=None):\n",
    "        with tf.device(device):\n",
    "            if rand_vec == None:\n",
    "                rand_vec = random.normal(shape=(100, self.latent_dim))\n",
    "            return tf.sigmoid(self.decode(rand_vec)) # binarize the result for visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and train model\n",
    "vae = VAE(latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define preliminary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct our loss function, let us define a few variables as follows: \n",
    "1. $x$: input data, or evidence (in our case, images)\n",
    "2. $z$: sampled latent representation from $p(z|x)$\n",
    "3. $p(x)$: evidence distribution\n",
    "4. $p(z)$: prior distribution\n",
    "5. $p(z|x)$: posterior distribution, which defines the encoder of our VAE\n",
    "6. $p(x|z)$: likelihood probability, which defines the decoder of our VAE\n",
    "\n",
    "Following the reference, we have the loss function given by $$\\text{loss} = C||x-\\hat{x}||^2 + \\text{KL}(N(\\mu_{x}, \\theta_{x}), N(0,1)),$$\n",
    "where KL is the KL divergence of the two Gaussians and $C > 0$. We use $\\hat{x}$ to denote the likelihhod pobability p(x|z), and assume that $p(z)$ follows the standard Gaussian and $p(z|x)$ follows a Gauussian characterized by the two output of the encoder network (the mean and log variance). Because $p(z|x)$ is intractable, we use $q(z|x) to denote the approximation of $p(z|x)$. Overall, this loss in very interpretable, as the first likelihood term characterizes the construction error (it does not need to be MSE, and we use cross entropy in our code) and the second KL term is for the regularization of the network (so that our latent space becomes more continuous and complete, which enables the generative proceedur).\n",
    "\n",
    "Now, rather than implementating this loss function, we will construct another loss function that is more easily implementable. Our objective function is (not the loss)\n",
    "$$\\text{argmin}\\left[C||x-\\hat{x}||^2 + KL\\left(q(z|x), p(z)\\right)\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}p(x|z)\\right] - KL\\left(q(z|x), p(z)\\right)\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}p(x|z)\\right] + \\int q(z|x)\\text{log}\\left(\\frac{p(z)}{q(z|x)}\\right)\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}p(x|z)\\right] + \\mathbb{E}_{z \\sim q(z|x)}\\text{log}\\left(\\frac{p(z)}{q(z|x)}\\right)\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}p(x|z) + \\text{log}\\left(\\frac{p(z)}{q(z|x)}\\right)\\right]\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}\\left(\\frac{p(x|z)p(z)}{q(z|x)}\\right)\\right]\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}p(x|z) + \\text{log}p(z) - \\text{log}q(z|x)\\right]\\right].$$\n",
    "\n",
    "This objective function gives a new loss\n",
    "$$\\text{loss} = \\text{log}p(x|z) + \\text{log}p(z) - \\text{log}q(z|x).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal(sample, mean, logvar):\n",
    "    with tf.device(device):\n",
    "        prob = -0.5 * ((sample - mean) ** 2.0 * tf.exp(-logvar) + logvar + tf.math.log(2.0 * np.pi))\n",
    "        return tf.reduce_sum(prob, axis=1)\n",
    "\n",
    "def get_loss(model, x):\n",
    "    with tf.device(device):\n",
    "        mean, logvar = model.encode(x) # defining q(z|x)\n",
    "        z = model.reparameterize(mean, logvar) # sampled from q(z|x)\n",
    "        xhat = model.decode(z) # generated by obtaining p(x|z)\n",
    "        # print('x: ', x.shape)\n",
    "        # print('mean, logvar: ', mean.shape)\n",
    "        # print('z: ', z.shape)\n",
    "        # print('xhat: ', xhat.shape)\n",
    "        prob = nn.sigmoid_cross_entropy_with_logits(labels=x, logits=xhat)\n",
    "\n",
    "        logpxz = -tf.reduce_sum(prob, axis=[1,2,3]) # just reconstruction error\n",
    "        logpz = log_normal(z, mean, logvar) # standard Gaussian (assumed)\n",
    "        logqzx = log_normal(z, mean, logvar) # Gaussian obtained through encoder\n",
    "\n",
    "        # return the average value for each sample within this batch\n",
    "        return -tf.reduce_mean(logpxz + logpz - logqzx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''use Adam'''\n",
    "def train_per_batch(model, x):\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    with tf.device(device):\n",
    "        with tf.GradientTape() as gt:\n",
    "            loss = get_loss(model, x)\n",
    "            gradient = gt.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "def train(model, epochs, x, x_test_sample=None, z_random_noise=None):\n",
    "    # for each epoch\n",
    "    with tf.device(device):\n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()\n",
    "            train_loss = metrics.Mean()\n",
    "            for x_batch in x:\n",
    "                train_loss(train_per_batch(model, x_batch))\n",
    "            time_elapsed = time.time() - start_time\n",
    "            loss = train_loss.result()\n",
    "            if math.isnan(loss):\n",
    "                print('ERROR: loss is not computable')\n",
    "                exit(0)\n",
    "            print(f'Epoch: {epoch}, train loss: {loss}, time elapsed: {time_elapsed}')\n",
    "\n",
    "            if (epoch+1) % 10 == 0:\n",
    "                if x_test_sample is not None: \n",
    "                    pred = predict(model, x_test_sample)\n",
    "                    save_img(pred, f'reconstructed_epoch{epoch+1}_ld{latent_dim}_batch{batch_size}')\n",
    "                if z_random_noise is not None:\n",
    "                    save_img(z_random_noise, f'generated_epoch{epoch+1}_ld{latent_dim}_batch{batch_size}')\n",
    "\n",
    "def predict(model, x):\n",
    "    with tf.device(device):\n",
    "        mean, logvar = model.encode(x)\n",
    "        z = model.reparameterize(mean, logvar) \n",
    "        return model.sample(z) \n",
    "\n",
    "def generate(model):\n",
    "    with tf.device(device):\n",
    "        random_vector_z = tf.random.normal(shape=[16, model.latent_dim])\n",
    "        generated = model.sample(random_vector_z)\n",
    "        return generated\n",
    "\n",
    "def save_img(pred, filename):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(pred[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(f'./images/{filename}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "for test_batch in x_test_digits.take(1):\n",
    "    x_test_sample = test_batch[0:16, :, :, :]\n",
    "z_random_noise = generate(model=vae)\n",
    "train(model=vae, epochs=20, x=x_train_digits, x_test_sample=x_test_sample, z_random_noise=z_random_noise)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88bb0f5aeba86b8857a89854e1b72d899daa3df0ccd17c65f10c2af66593c562"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
