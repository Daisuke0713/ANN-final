{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional VAEs for MNIST handwritten-digits and fashion datset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "Implemented based on the following references: <br>\n",
    "    (1) https://www.tensorflow.org/tutorials/generative/cvae <br>\n",
    "    (2) https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73 <br>\n",
    "    (3) https://arxiv.org/pdf/1907.08956.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warnings\n",
    "This Jupyter notebook is assumed to be executed on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GitHub repo clone/pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Daisuke0713/ANN-final.git\n",
    "%cd ./ANN-final/VAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras, random, nn\n",
    "from tensorflow import data\n",
    "from keras import Model, Sequential, optimizers, metrics, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.layers import InputLayer, Dense, Conv2D, Conv2DTranspose, Reshape, Flatten, Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU/CPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = tf.test.gpu_device_name()\n",
    "cpu_device = '/cpu:0'\n",
    "# set CPU the device for now\n",
    "device = gpu_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpu_device != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(gpu_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congif Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "latent_dim = 100\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "(x_train_digits, _), (x_test_digits, _) = keras.datasets.mnist.load_data()\n",
    "(x_train_fashion, _), (x_test_fashion, _) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "def preprocess_digits_image_data(data):\n",
    "    # reshape, normalize, and binarize (gray) data\n",
    "    image_data = data.reshape((data.shape[0], data.shape[1], data.shape[2], 1)) / 255.\n",
    "    return np.where(image_data < 0.5, 0.0, 1.0).astype('float32')\n",
    "\n",
    "def preprocess_fashion_image_data(data):\n",
    "    # reshape and normalize\n",
    "    shape = data.shape\n",
    "    image_data = data.reshape((shape[0], shape[1], shape[2], 1)) / 255.\n",
    "    return image_data.astype('float32')\n",
    "\n",
    "# preprocess data\n",
    "x_train_digits = preprocess_digits_image_data(x_train_digits)\n",
    "x_test_digits = preprocess_digits_image_data(x_test_digits)\n",
    "\n",
    "x_train_fashion = preprocess_fashion_image_data(x_train_fashion)\n",
    "x_test_fashion = preprocess_fashion_image_data(x_test_fashion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct our loss function, let us define a few variables as follows: \n",
    "1. $x$: input data, or evidence (in our case, images)\n",
    "2. $z$: sampled latent representation from $p(z|x)$\n",
    "3. $p(x)$: evidence distribution\n",
    "4. $p(z)$: prior distribution\n",
    "5. $p(z|x)$: posterior distribution, which defines the encoder of our VAE\n",
    "6. $p(x|z)$: likelihood probability, which defines the decoder of our VAE\n",
    "\n",
    "Following the reference, we have the loss function given by $$\\text{loss} = C||x-\\hat{x}||^2 + \\text{KL}(N(\\mu_{x}, \\theta_{x}), N(0,1)),$$\n",
    "where KL is the KL divergence of the two Gaussians and $C > 0$. We use $\\hat{x}$ to denote the likelihhod pobability p(x|z), and assume that $p(z)$ follows the standard Gaussian and $p(z|x)$ follows a Gauussian characterized by the two output of the encoder network (the mean and log variance). Because $p(z|x)$ is intractable, we use $q(z|x) to denote the approximation of $p(z|x)$. Overall, this loss in very interpretable, as the first likelihood term characterizes the construction error (it does not need to be MSE, and we use cross entropy in our code) and the second KL term is for the regularization of the network (so that our latent space becomes more continuous and complete, which enables the generative proceedur).\n",
    "\n",
    "Now, rather than implementating this loss function, we will construct another loss function that is more easily implementable. Our objective function is (not the loss)\n",
    "$$\\text{argmin}\\left[C||x-\\hat{x}||^2 + KL\\left(q(z|x), p(z)\\right)\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}p(x|z)\\right] - KL\\left(q(z|x), p(z)\\right)\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}p(x|z)\\right] + \\int q(z|x)\\text{log}\\left(\\frac{p(z)}{q(z|x)}\\right)\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}p(x|z)\\right] + \\mathbb{E}_{z \\sim q(z|x)}\\text{log}\\left(\\frac{p(z)}{q(z|x)}\\right)\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}p(x|z) + \\text{log}\\left(\\frac{p(z)}{q(z|x)}\\right)\\right]\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}\\left(\\frac{p(x|z)p(z)}{q(z|x)}\\right)\\right]\\right]$$\n",
    "$$= \\text{argmax}\\left[\\mathbb{E}_{z \\sim q(z|x)}\\left[\\text{log}p(x|z) + \\text{log}p(z) - \\text{log}q(z|x)\\right]\\right].$$\n",
    "\n",
    "This objective function gives a new loss\n",
    "$$\\text{loss} = \\text{log}p(x|z) + \\text{log}p(z) - \\text{log}q(z|x).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal(sample, mean, logvar):\n",
    "    with tf.device(device):\n",
    "        prob = -0.5 * ((sample - mean) ** 2.0 * tf.exp(-logvar) + logvar + tf.math.log(2.0 * np.pi))\n",
    "        return tf.reduce_sum(prob, axis=1)\n",
    "\n",
    "def get_loss(model, x):\n",
    "    with tf.device(device):\n",
    "        mean, logvar, z = model.encoder(x) # z sampled from q(z|x)\n",
    "        xhat = model.decoder(z) # generated by obtaining p(x|z)\n",
    "        prob = nn.sigmoid_cross_entropy_with_logits(labels=x, logits=xhat)\n",
    "\n",
    "        logpxz = -tf.reduce_sum(prob, axis=[1,2,3]) # just reconstruction error\n",
    "        logpz = log_normal(z, mean, logvar) # standard Gaussian (assumed)\n",
    "        logqzx = log_normal(z, mean, logvar) # Gaussian obtained through encoder\n",
    "\n",
    "        # return the average value for each sample within this batch\n",
    "        return -tf.reduce_mean(logpxz + logpz - logqzx)\n",
    "\n",
    "def get_default_loss(model, x):\n",
    "    with tf.device(device):\n",
    "        mean, logvar, z = model.encoder(x)\n",
    "        xhat = model.decoder(z)\n",
    "        rl = tf.reduce_mean(keras.losses.binary_crossentropy(x, xhat))*28*28\n",
    "        kl = tf.reduce_mean(1+logvar-tf.square(mean)-tf.exp(logvar)) * -0.5\n",
    "        return rl + kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define VAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Functional)        [(None, 100),             498568    \n",
      "                              (None, 100),                       \n",
      "                              (None, 100)]                       \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 28, 28, 1)         391169    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 889,737\n",
      "Trainable params: 889,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''Sampling layer'''\n",
    "class Sampling(Layer):\n",
    "\n",
    "    def call(self, prob):\n",
    "        mean, logvar = tf.split(prob, num_or_size_splits=2, axis=1)\n",
    "        e = random.normal(shape=(tf.shape(mean)[0], tf.shape(mean)[1]))\n",
    "        z = mean + e * tf.exp(logvar * 0.5)\n",
    "        return mean, logvar, z\n",
    "\n",
    "'''Basic Convolutional VAE'''\n",
    "class VAE(Model):\n",
    "\n",
    "    def __init__(self, latent_dim, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = self.get_encoder()\n",
    "        self.decoder = self.get_decoder()\n",
    "\n",
    "    '''encoder + reparametrization (i.e., sampling) layer'''\n",
    "    def get_encoder(self):\n",
    "        input_x = Input(shape=(28,28,1))\n",
    "        x = Conv2D(filters=64, kernel_size=3, strides=(2,2), activation='relu')(input_x)\n",
    "        x = Conv2D(filters=64, kernel_size=3, strides=(2,2), activation='relu')(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(self.latent_dim * 2)(x)\n",
    "        (mean, logvar, z) = Sampling()(x)\n",
    "        return Model(input_x, [mean, logvar, z], name=\"encoder\")\n",
    "\n",
    "    '''decoder'''\n",
    "    def get_decoder(self):\n",
    "        input_z = Input(shape=(self.latent_dim,))\n",
    "        z = Dense(7*7*64, activation=\"relu\")(input_z)\n",
    "        z = Reshape((7, 7, 64))(z)\n",
    "        z = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(z)\n",
    "        z = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(z)\n",
    "        xhat = Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', activation='sigmoid')(z)\n",
    "        return  Model(input_z, xhat, name=\"decoder\")\n",
    "\n",
    "    '''train'''\n",
    "    def train_step(self, x):\n",
    "        with tf.device(device):\n",
    "            x = x[0] if isinstance(x, tuple) else x\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss = get_default_loss(self, x)\n",
    "            gradient = tape.gradient(loss, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(gradient, self.trainable_weights))\n",
    "            return {\"loss\": loss}\n",
    "\n",
    "    def call(self, inputs):\n",
    "       pass\n",
    "\n",
    "# instansiate model\n",
    "vae = VAE(latent_dim=latent_dim)\n",
    "vae.compile(optimizer=Adam(learning_rate=learning_rate))\n",
    "vae.build(input_shape=(28,28,1))\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''define call backs'''\n",
    "def generate():\n",
    "    ramdom_vector_z = np.random.normal(loc=0, scale=1, size=(16, latent_dim))\n",
    "    generated = vae.decoder(ramdom_vector_z)\n",
    "    return generated\n",
    "\n",
    "def save_img(imgs, filename=None):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(f'./images/{filename}.png')\n",
    "\n",
    "def call_back(epoch, _):\n",
    "    if epoch % 5 == 0:\n",
    "        random_vector_z = tf.random.normal(shape=(16, latent_dim))\n",
    "        generated = vae.decoder(random_vector_z)\n",
    "        save_img(generated, f'epoch{epoch}_batch{batch_size}_latent{latent_dim}')\n",
    "\n",
    "callbacks = LambdaCallback(on_epoch_end=call_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x=x_train_digits, epochs=epochs, batch_size=batch_size, callbacks=[callbacks])\n",
    "vae.save_weights('base')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88bb0f5aeba86b8857a89854e1b72d899daa3df0ccd17c65f10c2af66593c562"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
